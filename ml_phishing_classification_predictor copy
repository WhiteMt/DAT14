#weka .arff training data set to csv
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Go to https://archive.ics.uci.edu/ml/machine-learning-databases/00327/Training%20Dataset.arff\n",
    "- right click on the page and click 'Save As' and name something ending with .arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mYou are using pip version 7.0.1, however version 7.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied (use --upgrade to upgrade): liac-arff in ./anaconda/lib/python2.7/site-packages\n"
     ]
    }
   ],
   "source": [
    "# install 'liac-arff', a python module that can load arff files\n",
    "!pip install liac-arff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas and arff\n",
    "import pandas as pd\n",
    "import arff\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the data with the path to the file and the name you gave it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data, which is now stored in a dictionary\n",
    "\n",
    "data_arff = arff.load(open('TheDirectoryItIsIn/TheNameYouGaveIt.arff', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the column names by calling the key 'attributes' and getting the first value in each tuple\n",
    "column_names = [x[0] for x in data_arff['attributes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data into a pandas data frame and set the column names\n",
    "df = pd.DataFrame(data_arff['data'], columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change the column types from 'object' to 'int'\n",
    "df = df.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

#df to csv
df = pd.read_csv('phishingdata.csv')

# package import

import pandas as pd
import numpy as np 
import arff
import urllib2
import matplotlib.pyplot as plt
import re
# importing library ^^ for plot production and interactive 2D data visualizations

from sklearn.ensemble import RandomForestClassifier 
%matplotlib inline
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import (classification_report, confusion_matrix, roc_curve, auc,
                             accuracy_score, roc_auc_score)

#plot correlation matrix visualization
#variable
df_corr = df.corr()
#set size
f, ax = plt.subplots(figsize=(9, 9))   
#color palate
cmap = sns.diverging_palette(220, 10, as_cmap=True)
# plotting actual data
sns.corrplot(df_corr, annot=False, sig_stars=False,
             diag_names=False, cmap=cmap, ax=ax)
#<matplotlib.axes._subplots.AxesSubplot at 0x10fde06d0>

#ordering correlation + or - first, from highest to lowest correlation, start at first integer
corr_series = df_corr.Result.abs().order(ascending = False)[1:]   

#plotting up to the 10th
corr_series[:10].plot(kind = 'bar');   

corr_idx = corr_series [:10].index

df.groupby('URL_of_Anchor').Result.mean()
#taking attribute of -1 and adding up all results
#98% if it is -1 it will be either a nonfishing and 1 a fishing email 

URL_df.head(10)
URL_df[URL_df.URL_of_Anchor == -1]
#Results is 1 when email with attribute of -1

#grouping feature to view mean and count
grouped1 = df.groupby('having_IP_Address').Result.agg(('mean', 'count'))
#list comprehension appending collumn name to indeces
grouped1.index = ['having_IP_Address' + str(string) for string in grouped1.index]
grouped1

varsGrouped = pd.DataFrame()
# creating for loop for data frame 
for col in corr_series.index:
       
    grouped = df.groupby(col).Result.agg(['mean', 'count'])
# grouping by a single column
    grouped.index = [col + str(string) for string in grouped.index]
    varsGrouped = pd.concat([varsGrouped, grouped])

    varsGrouped

    #varsGrouped['count']
varsGrouped['count'].order(ascending = False).plot(kind = 'bar', figsize = (12,6));

#importing scatter plot
from matplotlib.artist import setp
fig = plt.gcf()
# setting axes and size for scatter plot
fig.set_size_inches(18.5, 10.5)
x = range(len(varsGrouped.index))
y = varsGrouped['mean']

# function for setting vertical labels to the x axis
my_xticks = varsGrouped.index

plt.xticks(x, my_xticks)
plt.scatter(x,
           y,
           s = varsGrouped['count'],
           alpha = .5)
plt.xticks(rotation=90)
plt.ylim(-0.05,1.05)
plt.show()

corr_series.plot(kind = 'bar')

from sklearn.cross_validation import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)

from sklearn import neighbors
n_neighbors=range(1, 101, 2)
scores = []
for n in n_neighbors:
    clf = neighbors.KNeighborsClassifier(n)
    clf.fit(X_train, y_train)
    scores.append(clf.score(X_test, y_test))
# connect data to classification model and predictive ml alogrithm using Knearest neighbors   

# accuracy score plotted over 100 values of K
plt.plot(n_neighbors, scores, linewidth=3.0)

knn = neighbors.KNeighborsClassifier(1)
svc = svm.SVC(kernel='linear', probability=True)
nb = GaussianNB()
lr = LogisticRegression()
rf = RandomForestClassifier(n_estimators=100)

k = str(rf).split('(')
# getting first item in the list
k[0]
score_dict = {}

def plot_confusion_matrix(cm, cmap, title='Confusion matrix'):
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    plt.tight_layout()
    plt.ylabel('True label')
    # True label = what it actually is
    plt.xlabel('Predicted label')

def plot_roc_curve(y_test, p_proba):
    # calculates: false positive rate, true positive rate, 
    fpr, tpr, thresholds = roc_curve(y_test, p_proba[:, 1])
    
    roc_auc = auc(fpr, tpr)
    # Plot ROC curve
    plt.plot(fpr, tpr, label= 'AUC = %0.3f' % roc_auc)
    plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.0])
    plt.xlabel('False Positive Rate or (1 - Specifity)')
    plt.ylabel('True Positive Rate or (Sensitivity)')
    plt.title('ROC')
    plt.legend(loc="lower right")

def plt_Model(X_train, y_train, X_test, y_test, clf, score_dict, cmap = plt.cm.Blues):
    fig = plt.figure()
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print "Accuracy Score: ", accuracy_score(y_test, y_pred)
    
    # making score dict
    clf_list = str(clf).split('(')
    score_dict[clf_list[0]] = accuracy_score(y_test, y_pred)
    
    cm = confusion_matrix(y_test, y_pred)
    print "\nConfusion Matrix:\n", cm
    plot_confusion_matrix(cm, cmap, title='Confusion matrix')
    p_proba = clf.predict_proba(X_test)
    fig = plt.figure()
    plot_roc_curve(y_test, p_proba)

plt_Model(X_train, y_train, X_test, y_test, knn, score_dict, cmap=plt.cm.Blues)

plt_Model(X_train, y_train, X_test, y_test, svc, score_dict, cmap=plt.cm.BrBG)
plt_Model(X_train, y_train, X_test, y_test, nb, score_dict, cmap=plt.cm.RdPu)
plt_Model(X_train, y_train, X_test, y_test, lr, score_dict, cmap=plt.cm.Pastel1_r)   
plt_Model(X_train, y_train, X_test, y_test, rf, score_dict, cmap=plt.cm.ocean)

rf.fit(X_train, y_train)
score_dict.keys()
score_df = pd.DataFrame(score_dict.values(), index = score_dict.keys(), columns = ['accuracy_score'])
score_df.plot(kind = 'bar', ylim= (.9,1));

fi = sorted(zip(rf.feature_importances_, df.columns), reverse=True)

fi_df = pd.DataFrame(fi).rename(columns = {0: 'feature_importance', 1 : 'column_name'}).set_index(['column_name'])

fi_df.plot(kind = 'bar', ylim= (0,.3));

fi_df.ix[:5].plot(kind = 'bar', ylim= (0,.3));

fi_df.head()

df.columns

df.describe()


